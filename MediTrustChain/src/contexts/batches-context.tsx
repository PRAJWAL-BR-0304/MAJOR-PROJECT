"use client";

import type { ReactNode } from "react";
import { createContext, useContext, useState, useMemo, useEffect, useCallback } from "react";
import { format } from "date-fns";
import { checkForAnomalies } from "@/ai/flows/anomaly-detection-flow";
import { useNotifications } from "./notifications-context";
import { fetchBatches, upsertBatch, addBatchHistory, updateBatchStatusInDb } from "@/lib/supabase/batches";
import { saveAnomaly, notifyRegulators } from "@/lib/supabase/alerts";
import { useCbacAuth } from "./cbac-auth-context";
import { createClient } from "@/lib/supabase/client";
import { logBatchAction } from "@/lib/audit/logger";
import { getUserIdentity } from "@/lib/cbac/access-control";

// Batch status type matching V2 strict state machine:
// Pending â†’ Approved â†’ In-Transit â†’ At-Pharmacy â†’ Sold
export type BatchStatus = "Pending" | "Approved" | "Rejected" | "In-Transit" | "At-Pharmacy" | "Sold" | "Expired" | "Recalled";

export type BatchHistoryEvent = {
  location: string;
  timestamp: string;
  status: BatchStatus;
};

export type Batch = {
  id: string;
  name: string;
  mfg: string;
  exp: string;
  qty: number;
  status: BatchStatus;
  manufacturer?: string;
  organization_id?: string; // For data isolation validation
  history: BatchHistoryEvent[];
  anomalyReason?: string;
  // V2: On-chain data hash computed at creation (IMMUTABLE)
  // This is the hash returned from the blockchain createBatch transaction
  dataHash?: string;
};

const initialBatches: Batch[] = [];

interface BatchesContextType {
  batches: Batch[];
  isLoading: boolean;
  addBatch: (batch: Omit<Batch, "status" | "history">) => Promise<Batch>;
  updateBatchStatus: (batchId: string, status: BatchStatus, location?: string, anomalyReason?: string) => Promise<Batch | undefined>;
  updateBatchLocation: (batchId: string, location: string) => Promise<Batch | undefined>;
}

const BatchesContext = createContext<BatchesContextType | undefined>(undefined);

export function BatchesProvider({ children }: { children: ReactNode }) {
  const [batches, setBatches] = useState<Batch[]>([]);
  const [isMounted, setIsMounted] = useState(false);
  const [isLoading, setIsLoading] = useState(true);
  const notifications = useNotifications();
  const { user, session, organization } = useCbacAuth();
  const supabase = createClient();

  // Initial data load â€” Supabase is the SOLE source of truth
  useEffect(() => {
    async function loadInitialData() {
      setIsLoading(true);
      try {
        if (user) {
          console.log("ðŸ”„ Fetching batches from Supabase...");
          console.log("ðŸ‘¤ User ID:", user.id);
          console.log("ðŸ“ User org_id from metadata:", user.user_metadata?.organization_id);

          const remoteBatches = await fetchBatches();
          console.log("ðŸ“¦ Fetched batches from database:", remoteBatches?.length || 0);

          // Trust RLS - database already filters by organization
          // Only do client-side validation as defense-in-depth if metadata is available
          const userOrgId = user.user_metadata?.organization_id;

          // Check if user is admin
          const supabase = createClient();
          const { data: adminUser } = await supabase
            .from('admin_users')
            .select('id')
            .eq('id', user.id)
            .eq('is_active', true)
            .maybeSingle();

          const isAdmin = !!adminUser;
          console.log("ðŸ‘‘ Is admin:", isAdmin);

          // RELAXED FILTERING: Trust RLS, only filter if we have valid org_id
          // This allows cross-org supply chain visibility while RLS handles security
          let validatedBatches = remoteBatches || [];

          if (!isAdmin && userOrgId) {
            // Only filter if user has org_id in metadata
            validatedBatches = validatedBatches.filter(batch => {
              // Allow batches with no organization_id (legacy) or matching org
              if (!batch.organization_id) return true;
              return batch.organization_id === userOrgId;
            });
            console.log(`ðŸ”’ Filtered to ${validatedBatches.length} batches for org ${userOrgId}`);
          }

          setBatches(validatedBatches);
        } else {
          setBatches([]);
        }
      } catch (error) {
        console.error("Failed to load batches:", error);
        notifications.addNotification({
          type: "error",
          message: "Failed to load batches from database",
          duration: 5000,
        });
      } finally {
        setIsLoading(false);
      }
    }

    if (isMounted) {
      loadInitialData();
    }
  }, [user, isMounted, notifications]); // Removed supabase dependency to prevent re-runs

  // Real-time updates subscription
  useEffect(() => {
    if (!user) return;

    const channel = supabase
      .channel('batches_changes')
      .on(
        'postgres_changes',
        {
          event: '*',
          schema: 'public',
          table: 'batches',
        },
        (payload) => {
          console.log('ðŸ”” Real-time update:', payload);
          // Refresh data on change
          if (payload.eventType === 'INSERT') {
            // We could append locally, but fetching ensures we get full history etc if needed
            // For now, let's just append the new record if it matches our org
            const newRecord = payload.new as any; // Cast to avoid type issues with raw payload
            // Basic transformation
            const newBatch: Batch = {
              id: newRecord.id,
              name: newRecord.name,
              mfg: newRecord.mfg,
              exp: newRecord.exp,
              qty: newRecord.qty,
              status: newRecord.status,
              manufacturer: newRecord.manufacturer,
              organization_id: newRecord.organization_id,
              history: [], // History comes separately
              anomalyReason: newRecord.anomaly_reason,
              dataHash: newRecord.data_hash
            };
            setBatches(current => [newBatch, ...current]);
          } else if (payload.eventType === 'UPDATE') {
            setBatches(current => current.map(b =>
              b.id === payload.new.id ? { ...b, ...payload.new as any } : b
            ));
          } else if (payload.eventType === 'DELETE') {
            setBatches(current => current.filter(b => b.id !== payload.old.id));
          }
        }
      )
      .subscribe();

    return () => {
      supabase.removeChannel(channel);
    };
  }, [user, supabase]);

  useEffect(() => {
    setIsMounted(true);
  }, []);

  const addBatch = async (newBatchData: Omit<Batch, "status" | "history">) => {
    if (!user) throw new Error("User must be logged in to create a batch");

    console.log("ðŸ”„ addBatch called with:", newBatchData);

    // Get user identity (role, organization, etc.)
    // Use fast path from metadata if available to avoid async heavy lifting
    const userMetadata = user.user_metadata;
    let userIdentity;

    if (userMetadata?.organization_id && userMetadata?.role) {
      console.log("âœ… Using user metadata for identity (fast path):", {
        organizationId: userMetadata.organization_id,
        isAdmin: userMetadata.is_admin,
        role: userMetadata.role
      });
      userIdentity = {
        organizationId: userMetadata.organization_id,
        organizationName: userMetadata.organization_name,
        role: userMetadata.role,
        isAdmin: !!userMetadata.is_admin
      };
    } else {
      console.log("âš ï¸ Metadata missing, fetching identity from DB (slow path)...");
      userIdentity = await getUserIdentity(user.id);
    }

    // STRICT Security Check: Ensure user belongs to the organization they are creating for
    if (newBatchData.organization_id && newBatchData.organization_id !== userIdentity.organizationId && !userIdentity.isAdmin) {
      console.error("âŒ Organization mismatch:", {
        request: newBatchData.organization_id,
        user: userIdentity.organizationId
      });
      throw new Error('Cannot create batch for different organization');
    }

    const historyEvent: BatchHistoryEvent = {
      location: newBatchData.manufacturer || "Unknown Manufacturer",
      timestamp: new Date().toISOString(),
      status: "Pending"
    };

    // Use user's organization_id for data isolation
    const organizationId = newBatchData.organization_id || userIdentity.organizationId;

    const newBatch: Batch = {
      ...newBatchData,
      organization_id: organizationId, // CRITICAL: Set organization_id for data isolation
      status: "Pending",
      history: [historyEvent]
    };

    console.log("âœ… New batch object created:", newBatch);

    // 1. CRITICAL: Persist to Supabase FIRST (blocking) â€” this is the source of truth
    try {
      // Get current session token to bypass auth client hang in batches.ts
      // OPTIMIZATION: Use session from context (synchronous) instead of getSession() (async/hanging)
      const token = session?.access_token;

      if (!token) console.warn("âš ï¸ No access token found in session context, upsertBatch might fail");

      await upsertBatch(newBatch, user.id, token);
      console.log("âœ… Batch saved to database with organization_id:", organizationId);
    } catch (error) {
      console.error("âŒ Failed to save batch to database:", error);
      throw new Error(`Failed to save batch: ${error instanceof Error ? error.message : String(error)}`);
    }

    // 2. Update local state AFTER successful DB write
    setBatches(prevBatches => [newBatch, ...prevBatches]);
    console.log("âœ… Local state updated");

    // 3. Persist history and audit log in background (non-critical)
    try {
      // Add initial history record
      addBatchHistory(newBatch.id, historyEvent, user.id).catch(err =>
        console.warn("Background history save failed:", err)
      );

      // Log audit action
      logBatchAction(
        user.id,
        "CREATE_BATCH",
        newBatch.id,
        { ...newBatch, organization_id: organizationId },
        "SUCCESS"
      ).catch(err => console.warn("Background audit log failed:", err));

      // 4. Verify AI compliance checks (async)
      checkForAnomalies(newBatch).then(anomalies => {
        if (anomalies.length > 0) {
          console.warn(`âš ï¸ ${anomalies.length} anomalies detected for batch ${newBatch.id}`);

          // Save anomalies to database
          anomalies.forEach(anomaly => {
            saveAnomaly({
              batch_id: newBatch.id,
              severity: anomaly.severity,
              description: anomaly.description,
              detected_at: new Date().toISOString(),
              is_resolved: false
            }).catch(e => console.error("Failed to save anomaly:", e));
          });

          // Notify regulators if needed
          notifyRegulators(newBatch.id, anomalies).catch(e =>
            console.error("Failed to notify regulators:", e)
          );
        }
      });
    } catch (error) {
      // Non-blocking errors
      console.warn("âš ï¸ Non-critical background task failed:", error);
    }

    return newBatch;
  };

  const updateBatchStatus = async (
    batchId: string,
    status: BatchStatus,
    location: string = "Unknown Location",
    anomalyReason?: string
  ) => {
    if (!user) throw new Error("User must be logged in to update batch status");

    const historyEvent: BatchHistoryEvent = {
      location,
      timestamp: new Date().toISOString(),
      status
    };

    // Optimistic update locally
    const originalBatches = [...batches];
    setBatches(prevBatches =>
      prevBatches.map(batch =>
        batch.id === batchId
          ? {
            ...batch,
            status,
            history: [...batch.history, historyEvent],
            anomalyReason
          }
          : batch
      )
    );

    try {
      // 1. Update status in DB (using unrestricted function for supply chain)
      await updateBatchStatusInDb(batchId, status, location, anomalyReason);

      // 2. Add history record
      await addBatchHistory(batchId, historyEvent, user.id);

      // 3. Log audit
      await logBatchAction(
        user.id,
        "UPDATE_STATUS",
        batchId,
        { oldStatus: batches.find(b => b.id === batchId)?.status, newStatus: status, location },
        "SUCCESS"
      );

      return batches.find(b => b.id === batchId);
    } catch (error) {
      console.error("Failed to update status in DB:", error);
      // Revert on failure
      setBatches(originalBatches);
      notifications.addNotification({
        type: "error",
        message: "Failed to update batch status",
        duration: 5000
      });
      return undefined;
    }
  };

  const updateBatchLocation = async (batchId: string, location: string) => {
    // Current status stays same, just location update? 
    // Usually location update comes with status change (e.g. In-Transit)
    // For now, let's assume it preserves current status
    const batch = batches.find(b => b.id === batchId);
    if (!batch) return undefined;

    return updateBatchStatus(batchId, batch.status, location);
  };

  const value = useMemo(
    () => ({
      batches,
      isLoading,
      addBatch,
      updateBatchStatus,
      updateBatchLocation,
    }),
    [batches, isLoading, user]
  );

  return <BatchesContext.Provider value={value}>{children}</BatchesContext.Provider>;
}

export function useBatches() {
  const context = useContext(BatchesContext);
  if (context === undefined) {
    throw new Error("useBatches must be used within a BatchesProvider");
  }
  return context;
}
